{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d8641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tracemalloc\n",
    "import random\n",
    "import os\n",
    "import psutil\n",
    "import shutil\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '16'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "import numexpr as ne\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import sys\n",
    "import ctypes\n",
    "import tensorflow as tf\n",
    "from client import Client\n",
    "from edgeserver import Edgeserver\n",
    "from server import Server \n",
    "from datasets_partitioning.mnist_cifar10 import get_dataset\n",
    "from datasets_partitioning.mnist_cifar10 import k_niid_equal_size_split\n",
    "from datasets_partitioning.mnist_cifar10 import k_niid_equal_size_split_1\n",
    "from datasets_partitioning.mnist_cifar10 import Gaussian_noise\n",
    "from datasets_partitioning.mnist_cifar10 import get_classes\n",
    "from datasets_partitioning.mnist_cifar10 import random_edges\n",
    "from datasets_partitioning.mnist_cifar10 import iid_edges\n",
    "from datasets_partitioning.mnist_cifar10 import niid_edges\n",
    "from datasets_partitioning.mnist_cifar10 import iid_equal_size_split\n",
    "from datasets_partitioning.mnist_cifar10 import iid_nequal_size_split\n",
    "from datasets_partitioning.mnist_cifar10 import niid_labeldis_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from model.initialize_model import create\n",
    "from tensorflow.keras.utils import plot_model,to_categorical\n",
    "from plots import client_plot\n",
    "\n",
    "\n",
    "# =============================================================================================================\n",
    "#                                 ðŸ”·               Partitioning                ðŸ”·\n",
    "# =============================================================================================================\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "dataset=\"mnist\"\n",
    "if dataset=='cifar10' or dataset==\"mnist\":\n",
    "    num_labels=10\n",
    "model=\"cnn1\"   #or cnn2, cnn3\n",
    "batch_size=32\n",
    "communication_round=3              \n",
    "epochs=10                          #  number of local update \n",
    "num_edge_aggregation=4             #  number of edge aggregation \n",
    "num_edges=3  \n",
    "num_clients=30 \n",
    "folder=\"IID-mnist\"\n",
    "fraction_clients=1              # fraction of participated clients\n",
    "lr=0.01\n",
    "val_ratio=0.1     \n",
    "#beta=0.5         \n",
    "number_labels=10\n",
    "image_shape=(28,28,1)\n",
    "loss=\"categorical_crossentropy\"      #optimizer is \"Adam\"\n",
    "metrics=[\"accuracy\"]\n",
    "verbose=0    \n",
    "seed=4   \n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "optimizer=tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "#     ********** Get dataset **********\n",
    "tracemalloc.start()\n",
    "process=psutil.Process()\n",
    "start_rss=process.memory_info().rss\n",
    "\n",
    "X_train ,Y_train,X_test,Y_test=get_dataset(dataset,model) \n",
    "#X_train ,Y_train,X_test,Y_test=X_train[:21000] ,Y_train[:21000],X_test[:9000],Y_test[:9000]\n",
    "\n",
    "#     ********** partitioning and assigning ********** \n",
    "print('1 : clients_iid (equal size)\\n'\n",
    "      '2 : clients_iid (nonequal size)\\n'\n",
    "      '3 : each client owns data samples of a fixed number of labels\\n'\n",
    "      '4 : each client(and edge) owns data samples of a different feature distribution\\n'\n",
    "      '5 : each client owns a proportion of the samples of each label\\n')\n",
    "flag1=int(input('select a number:')) \n",
    "print(\"\\nUsing a locally saved model?\\n\"\n",
    "        \"1 : YES\\n\"\n",
    "        \"0 : NO\\n\")\n",
    "replace=int(input('select a number:'))\n",
    "\n",
    "#     ***********clients_iid*****************\n",
    "if flag1 in (1,2):                                      \n",
    "    print('\\n** randomly are assigned clients to edgesevers **')\n",
    "    clients=[]\n",
    "    edges=[]\n",
    "    \n",
    "    if flag1==1:\n",
    "        train_partitions=iid_equal_size_split(X_train,Y_train,num_clients)\n",
    "        test_partitions=iid_equal_size_split(X_test,Y_test,num_clients)\n",
    "    else:\n",
    "        train_partitions=iid_nequal_size_split(X_train,Y_train,num_clients,beta)\n",
    "        test_partitions=iid_nequal_size_split(X_test,Y_test,num_clients,beta)\n",
    "        \n",
    "    for i in range(num_clients):\n",
    "        clients.append(Client(i,train_partitions[i],test_partitions[i],dataset,model,loss,metrics,\n",
    "                                                         lr,batch_size,image_shape)) \n",
    "    assigned_clients_list=random_edges(num_edges,num_clients) \n",
    "    for edgeid in range(num_edges):\n",
    "        edges.append(Edgeserver(edgeid,assigned_clients_list[edgeid],dataset,model,loss,metrics,lr,image_shape))\n",
    "        for client_name in assigned_clients_list[edgeid]:               \n",
    "            index=int(client_name.split('_')[1])-1               \n",
    "            edges[edgeid].client_registering(clients[index])\n",
    "    clients_per_edge=int(num_clients/num_edges)\n",
    "    server=Server(dataset,model,loss,metrics,lr,image_shape)   \n",
    "\n",
    "    print(tracemalloc.get_traced_memory()) \n",
    "    del X_train,Y_train,X_test,Y_test,train_partitions,test_partitions,assigned_clients_list\n",
    "    gc.collect()\n",
    "    print(tracemalloc.get_traced_memory()) \n",
    "    \n",
    "#     **************** partitioning and assigning from up to down ******************\n",
    "#     ********** each edge owns data samples of a fixed number of labels ********** \n",
    "elif flag1==3:                                       \n",
    "    clients_per_edge=int(num_clients/num_edges)\n",
    "    k1=int(input('\\nk1 : number of labels for each edge  ?  '))\n",
    "    k2=int(input('k2 : number of labels for clients per edge  ?  '))\n",
    "    print(f'\\n** assign each edge {clients_per_edge} clients with {k1} classes'\n",
    "          f'\\n** assign each client samples of {k2}  classes of {k1} edge classes')\n",
    "    \n",
    "    label_list=list(range(num_labels))\n",
    "    X_train,Y_train,X_test,Y_test,party_labels_list=k_niid_equal_size_split(X_train,Y_train,X_test,\n",
    "                                                                        Y_test,num_edges,label_list,k1,flag1)  \n",
    "    clients=[]\n",
    "    edges=[]\n",
    "    index=0  \n",
    "    for edgeid in range(num_edges):           \n",
    "        train_partitions,test_partitions=k_niid_equal_size_split(X_train[edgeid],Y_train[edgeid],X_test[edgeid],\n",
    "                                                Y_test[edgeid],clients_per_edge,party_labels_list[edgeid],k2)\n",
    "        assigned_clients=[]\n",
    "        for i in range(clients_per_edge):\n",
    "            clients.append(Client(index,train_partitions[i],test_partitions[i],dataset,model,loss,metrics,\n",
    "                                                         lr,batch_size,image_shape))   \n",
    "            assigned_clients.append(index)\n",
    "            index+=1\n",
    "        assigned_clients=list(map(lambda x :f'client_{x+1}',assigned_clients))\n",
    "        edges.append(Edgeserver(edgeid,assigned_clients,dataset,model,loss,metrics,lr,image_shape))\n",
    "        for client_name in assigned_clients:                 # client's name : 'client_k'\n",
    "            idx=int(client_name.split('_')[1])-1                # k-1\n",
    "            edges[edgeid].client_registering(clients[idx])\n",
    "        for i in range(clients_per_edge):\n",
    "            print(f'{edges[edgeid].cnames[i]}')\n",
    "        print(f'be assigned to {edges[edgeid].name}')\n",
    "    server=Server(dataset,model,loss,metrics,lr,image_shape)   \n",
    "\n",
    "    print(tracemalloc.get_traced_memory()) \n",
    "    del X_train,X_test,Y_train,Y_test,test_partitions,train_partitions\n",
    "    gc.collect()  \n",
    "    print(tracemalloc.get_traced_memory()) \n",
    "\n",
    "#     ********** each edge owns data samples of a different feature distribution ********** \n",
    "#     ***** each edge owns data samples of 10 labels but each client owns data samples of one or 10 labels ***** \n",
    "elif flag1==4:                                   \n",
    "    original_std=float(input('\\noriginal standard deviation for gaussian noise  ?  '))\n",
    "    k=int(input('k : number of labels for clients of each edge  ?  '))  \n",
    "    \n",
    "    X_train,Y_train=iid_equal_size_split(X_train,Y_train,num_edges,flag1) \n",
    "    X_test,Y_test=iid_equal_size_split(X_test,Y_test,num_edges,flag1)\n",
    "    #basic_std=0.1      \n",
    "    edges=[]\n",
    "    clients=[]\n",
    "    clients_per_edge=int(num_clients/num_edges)\n",
    "    labels_list=list(range(num_labels)) \n",
    "    mean=0      \n",
    "    index=0 \n",
    "    for edgeid in range(num_edges):\n",
    "        train_noisy_edge=Gaussian_noise(X_train[edgeid],original_std,edgeid,num_edges,mean)\n",
    "        test_noisy_edge=Gaussian_noise(X_test[edgeid],original_std,edgeid,num_edges,mean)\n",
    "        train_party_partitions,test_party_partitions=k_niid_equal_size_split(train_noisy_edge,Y_train,test_noisy_edge, \n",
    "                                                                             Y_test,clients_per_edge,labels_list,k)\n",
    "        assigned_clients=[]\n",
    "        for i in range(clients_per_edge):\n",
    "            clients.append(Client(index,train_party_partitions[i],test_party_partitions[i],dataset,model,loss,metrics,\n",
    "                                                         lr,batch_size,image_shape))  \n",
    "            assigned_clients.append(index)\n",
    "            index+=1\n",
    "        assigned_clients=list(map(lambda x :f'client_{x+1}',assigned_clients))\n",
    "        edges.append(Edgeserver(edgeid,assigned_clients,dataset,model,loss,metrics,lr,image_shape))\n",
    "        for client_name in assigned_clients:                  \n",
    "            idx=int(client_name.split('_')[1])-1                \n",
    "            edges[edgeid].client_registering(clients[idx])\n",
    "        for i in range(clients_per_edge):\n",
    "            print(f'{edges[edgeid].cnames[i]}')\n",
    "        print(f'be assigned to {edges[edgeid].name}')\n",
    "    server=Server(dataset,model,loss,metrics,lr,image_shape)   \n",
    "    \n",
    "    print(tracemalloc.get_traced_memory()) \n",
    "    del X_train,Y_train,X_test,Y_test,train_partitions,test_partitions,train_noisy_edge,test_noisy_edge,train_party_partitions,test_party_partitions\n",
    "    gc.collect()\n",
    "    print(tracemalloc.get_traced_memory())\n",
    "    \n",
    "#     ************** each client owns a proportion of the samples of each label **************\n",
    "elif flag1==5:                       \n",
    "    train_partitions=niid_labeldis_split(X_train,Y_train,num_clients,'train',beta)\n",
    "    test_partitions=niid_labeldis_split(X_test,Y_test,num_clients,'test',beta)\n",
    "    clients=[]\n",
    "    edges=[]\n",
    "    clients_per_edge=int(num_clients/num_edges)\n",
    "    index=0  \n",
    "    for edgeid in range(num_edges):                           \n",
    "        assigned_clients=[]\n",
    "        for _ in range(clients_per_edge):\n",
    "            client_classes=get_classes(train_partitions[index])\n",
    "            clients.append(Client(index,train_partitions[index],test_partitions[index],dataset,model,loss,metrics,\n",
    "                                                         lr,batch_size,image_shape))  \n",
    "            assigned_clients.append(index)\n",
    "            index+=1\n",
    "        assigned_clients=list(map(lambda x :f'client_{x+1}',assigned_clients))\n",
    "        edges.append(Edgeserver(edgeid,assigned_clients,dataset,model,loss,metrics,lr,image_shape))\n",
    "        for client_name in assigned_clients:                 \n",
    "            idx=int(client_name.split('_')[1])-1               \n",
    "            edges[edgeid].client_registering(clients[idx])\n",
    "        for i in range(clients_per_edge):\n",
    "            print(f'{edges[edgeid].cnames[i]}')\n",
    "        print(f'be assigned to {edges[edgeid].name}')\n",
    "    server=Server(dataset,model,loss,metrics,lr,image_shape)   \n",
    "    \n",
    "    print(tracemalloc.get_traced_memory()) \n",
    "    del X_train,Y_train,X_test,Y_test,train_partitions,test_partitions\n",
    "    gc.collect()\n",
    "    print(tracemalloc.get_traced_memory()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4bf56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####     ********** Select type of server aggregation ********** \n",
    "path=fr'.\\results\\edges_models\\{folder}\\\\'                     \n",
    "for file_name in os.listdir(path):\n",
    "    file=path+file_name\n",
    "    if os.path.isfile(file):\n",
    "        os.remove(file)\n",
    "        \n",
    "path=fr'.\\results\\edges_models\\{folder}\\\\'                       \n",
    "for file_name in os.listdir(path):\n",
    "    file=path+file_name\n",
    "    shutil.rmtree(file)\n",
    "    \n",
    "path=fr'.\\results\\global_models\\{folder}\\\\'                    \n",
    "for file_name in os.listdir(path):\n",
    "    file=path+file_name\n",
    "    if os.path.isfile(file):\n",
    "        os.remove(file)\n",
    "        \n",
    "path=fr'.\\results\\fig\\{folder}\\\\'                        \n",
    "for file_name in os.listdir(path):\n",
    "    file=path+file_name\n",
    "    if os.path.isfile(file):\n",
    "        os.remove(file)\n",
    "print('method_1(m1) : uses number of samples of all clients \\nmethod_2(m2) :uses number of samples of the the participated clients...')\n",
    "type_of_server_agg=input('\\nselect a method for server aggregation:')\n",
    "\n",
    "# assigning edges to server \n",
    "for edge in edges:                                   \n",
    "    server.edgeserver_registering(edge)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f26351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#                       ðŸ”·     GLOBAL TRAINING PHASE         ðŸ”·\n",
    "# =============================================================================\n",
    "\n",
    "server.model.save(fr\".\\results\\global_models\\{folder}\\itr_0.h5\")\n",
    "for comm_r in range(communication_round):    \n",
    "  \n",
    "    print(f'===================================={comm_r+1} c_round...start================================================')\n",
    "    for edge in edges:\n",
    "        server.send_to_edgeserver(edge) \n",
    "                  \n",
    "    #buffer is cleared              \n",
    "    server.refresh_server() \n",
    "\n",
    "    # my assumption: all edges participate in training phase in each communication round             \n",
    "    for num_agg in range(num_edge_aggregation):\n",
    "        print(f'--------------------------------------{num_agg+1} agg...start---------------------------------------') \n",
    "        for edge in edges:\n",
    "            print(f'************{edge.name}******************start')\n",
    "\n",
    "            # buffer & participated_sample are cleared\n",
    "            edge.refresh_edgeserver()\n",
    "                              \n",
    "            #fraction of clients of each edge participate ...\n",
    "            selected_clients_num=max(int(clients_per_edge*fraction_clients),1)\n",
    "            selected_clients_name=np.random.choice(edge.cnames,selected_clients_num,replace=False)\n",
    "            for client_name in selected_clients_name:                 \n",
    "                index=int(client_name.split('_')[1])-1               \n",
    "                edge.client_registering(clients[index])               # parti.._sample\n",
    "            \n",
    "            for client_name in selected_clients_name: \n",
    "                index=int(client_name.split('_')[1])-1\n",
    "                edge.send_to_client(clients[index])    \n",
    "                for i in range(8):\n",
    "                    print(np.testing.assert_allclose(edge.model.get_weights()[i],clients[index].model.get_weights()[i]))\n",
    "                \n",
    "                print(f\"\\n--------------------------------> {client_name} be selected:\")\n",
    "                if comm_r!=0 or num_agg!=0:\n",
    "                    clients[index].local_model_train(epochs,batch_size,verbose,folder,comm_r,num_agg)   \n",
    "                else:\n",
    "                    if replace==1:\n",
    "                        clients[index].model=load_model(fr\".\\results\\clients_models\\{folder}\\{clients[index].name}.h5\")\n",
    "                    else:\n",
    "                        clients[index].local_model_train(epochs,batch_size,verbose,folder,comm_r,num_agg)  \n",
    "                        clients[index].model.save(fr\".\\results\\clients_models\\{folder}\\{clients[index].name}.h5\")\n",
    "                clients[index].send_to_edgeserver(edge)               # buffer\n",
    "            \n",
    "                for i in range(8):\n",
    "                    print(np.testing.assert_allclose(edge.buffer[client_name][i],clients[index].model.get_weights()[i]))\n",
    "                print(edge.participated_sample[client_name]==clients[index].train_num)\n",
    "                \n",
    "            edge.aggregate(comm_r,num_agg,folder)\n",
    "\n",
    "            print(f'************{edge.name}******************end')\n",
    "    #************end for/// iteration in edges\n",
    "        print(f'--------------------------------------{num_agg+1} agg...end---------------------------------------')\n",
    "    #*********** end for///edge aggregation        \n",
    "                  \n",
    "    # begin server aggregation\n",
    "    if type_of_server_agg=='m1':\n",
    "        for edge in edges:                            \n",
    "            edge.send_to_server(server)     # server' buffer\n",
    "            for i in range(8):\n",
    "                print(np.testing.assert_allclose(edge.model.get_weights()[i],server.buffer[edge.name][i]))\n",
    "                    \n",
    "        server.aggregate_method1(comm_r,folder)\n",
    "    else:        \n",
    "        num_samples_in_agg_for_edges=[]\n",
    "        for edge in edges:                            \n",
    "            edge.send_to_server(server)     # server' buffer\n",
    "            num_samples_in_agg_for_edges.append(sum(edge.num_samples_in_agg))    \n",
    "        server.aggregate_method2(num_samples_in_agg_for_edges,comm_r,folder)\n",
    "        for edge in edges():\n",
    "            edge.num_samples_in_agg.clear()\n",
    "\n",
    "    for client in clients:\n",
    "        acc=client.test_s(server)\n",
    "        client.acc.append(acc)\n",
    "    print(f'===================================={comm_r+1} c_round...end================================================')\n",
    "\n",
    "print(process.memory_info().rss-start_rss)\n",
    "print(tracemalloc.get_traced_memory())\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================================================================\n",
    "#   ðŸ”·   SEND GLOBAL MODEL TO CLIENTS AND ...         ðŸ”·\n",
    "# =================================================================================================\n",
    "for edge in edges:                                       \n",
    "    server.send_to_edgeserver(edge)  \n",
    "for edge in edges:\n",
    "    for client_name in edge.cnames:\n",
    "        index=int(client_name.split('_')[1])-1\n",
    "        edge.send_to_client(clients[index]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b011548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================================================\n",
    "#         ðŸ”·         TRANSFER LEARNING       ðŸ”·\n",
    "# =============================================================================\n",
    "if flag1==3:\n",
    "    for client in clients: \n",
    "        for layer in client.model.layers[:-2]:                     \n",
    "            layer.trainable=False\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.00001)\n",
    "        client.m_compile(loss=loss,optimizer=optimizer,metrics=metrics)\n",
    "        client.local_model_train(epochs=epochs,batch_size=batch_size,verbose=0)  #fit // epoch , bs Ù…ØªÙØ§ÙˆØª ÛŒØ§ Ù‚Ø¨Ù„ÛŒØŸ  \n",
    "        acc=client.test()\n",
    "        client.acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e06082",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "#     ðŸ”·     ACCURACY REPORT  (with personalized ,without personalized)        ðŸ”·\n",
    "# ==================================================================================\n",
    "for client in clients:\n",
    "    print(client.name,\":\",client.acc,\"------\",client.comm_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c45c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#                        ðŸ”·    clients PLOTS         ðŸ”·\n",
    "# =============================================================================\n",
    "c_model=create(dataset,model,loss,metrics,lr,image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in edges:\n",
    "    for client_name in edge.cnames:\n",
    "        index=int(client_name.split('_')[1])-1\n",
    "        file=fr'.\\results\\global_models\\{folder}\\itr_0.h5'\n",
    "        c_model.load_weights(file)\n",
    "        clients[index].predict(c_model,0)            # 0 -->  level 0 : sever model\n",
    "        for comm_r in range(communication_round):\n",
    "            \n",
    "            for num_agg in range(num_edge_aggregation):\n",
    "                file=fr'.\\results\\edges_models\\{folder}\\comm_{comm_r+1}_agg_{num_agg+1}_{client_name}.h5'\n",
    "                if os.path.isfile(file):\n",
    "                    c_model.load_weights(file)\n",
    "                    clients[index].predict(c_model,2)      #2 --> level 2 : client model\n",
    "                else:       \n",
    "                    clients[index].all_acc.append(clients[index].all_acc[-1])\n",
    "                    \n",
    "                file=fr'.\\results\\edges_models\\{folder}\\itr_{comm_r+1}\\agg_{num_agg+1}_{edge.name}.h5'\n",
    "                c_model.load_weights(file)\n",
    "                clients[index].predict(c_model,1)            # 1 --> level 1 : edge model \n",
    "                \n",
    "            file=fr'.\\results\\global_models\\{folder}\\itr_{comm_r+1}.h5'\n",
    "            c_model.load_weights(file)\n",
    "            clients[index].predict(c_model,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc47d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for client in clients:\n",
    "    client_plot(client,folder)      \n",
    "    \n",
    "for client in clients:\n",
    "    print(client.name ,\"--\", \"local :\",client.all_acc[1] , \"/\" , \"fed :\" ,client.all_acc[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-jupyter",
   "language": "python",
   "name": "env-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
